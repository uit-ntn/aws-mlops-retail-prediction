---
title: "Data Pipeline Optimization"
date: 2024-01-01T00:00:00Z
weight: 3
chapter: false
pre: "<b>3. </b>"
---

## ğŸ¯ Má»¥c tiÃªu Task 3

Táº¡o **S3 bucket** vÃ  tá»• chá»©c dá»¯ liá»‡u cho pipeline MLOps theo chuáº©n **raw â†’ silver â†’ gold â†’ artifacts**, chuyá»ƒn Ä‘á»•i CSV â†’ Parquet báº±ng **AWS Glue Studio (Visual ETL)** vÃ  **Ä‘o benchmark hiá»‡u nÄƒng Ä‘á»c/ghi**:

- Äo trÃªn **AWS CloudShell** (Ä‘á»c trá»±c tiáº¿p tá»« S3).
- Äo trÃªn **mÃ¡y local** (Windows, 16GB RAM).

Táº­p trung vÃ o:

- **Hiá»‡u nÄƒng Ä‘á»c/ghi**: CSV vs Parquet.
- **Dung lÆ°á»£ng lÆ°u trá»¯**: trÆ°á»›c/sau khi nÃ©n.
- **CÃ¡ch lÃ m**: tá»«ng bÆ°á»›c cá»¥ thá»ƒ, cÃ³ thá»ƒ tÃ¡i hiá»‡n.

{{% notice info %}}
**ğŸ’¡ Task 3 â€“ S3 Storage Optimization**

- âœ… Tá»‘i Æ°u **format**: Parquet + Snappy thay vÃ¬ CSV thuáº§n.
- âœ… Tá»‘i Æ°u **hiá»‡u nÄƒng Ä‘á»c/ghi** cho ETL & training.
- âœ… Tá»‘i Æ°u **dung lÆ°á»£ng lÆ°u trá»¯** (giáº£m Ä‘Ã¡ng ká»ƒ GB).
- âœ… Bá»• sung **benchmark thá»±c táº¿**: CloudShell + local.
  {{% /notice %}}

---
 
ğŸ“¥ **Input tá»« Task 2:** `IAM Roles & Audit` â€” account ID, IAM roles/policies and CloudTrail/audit setup required to create buckets, Glue roles and permissions.

## ğŸ”§ MÃ´i trÆ°á»ng lab thá»±c táº¿

- **Account ID:** `842676018087`
- **Region lab:** `us-east-1`
- **Bucket:** `mlops-retail-prediction-dev-842676018087`

Dataset chÃ­nh:

- `raw/transactions.csv`  
  â‰ˆ **4,593.65 MB**, **33,850,823 dÃ²ng**
- VÃ­ dá»¥ 1 file Parquet sau ETL:  
  `silver/shop_week=200607/run-1761638745394-part-block-0-0-r-00000-snappy.parquet`  
  â‰ˆ **458.45 MB**, **33,850,823 dÃ²ng**

---

## 1. Cáº¥u trÃºc & tá»• chá»©c S3 bucket

### 1.1. Cáº¥u trÃºc lÆ°u trá»¯ tá»•ng quÃ¡t

Ãp dá»¥ng cho má»i account, dÃ¹ng `{account-id}` lÃ m placeholder:

```text
s3://mlops-retail-prediction-dev-{account-id}/
â”œâ”€â”€ raw/        # dá»¯ liá»‡u CSV gá»‘c, immutable
â”œâ”€â”€ silver/     # dá»¯ liá»‡u Parquet Ä‘Ã£ lÃ m sáº¡ch / chuáº©n hÃ³a
â”œâ”€â”€ gold/       # features, aggregated datasets cho training/serving
â””â”€â”€ artifacts/  # model, metadata, logs, reports
```

Ã nghÄ©a:

- **raw/**: chá»‰ append, khÃ´ng sá»­a/xÃ³a â†’ phá»¥c vá»¥ audit & reprocessing.
- **silver/**: nÆ¡i lÆ°u Parquet tá»‘i Æ°u (schema chuáº©n, sáº¡ch).
- **gold/**: dataset cuá»‘i cÃ¹ng cho training/inference.
- **artifacts/**: model.tar.gz, notebook export, log, benchmark CSV,â€¦

---

### 1.2. Cáº¥u trÃºc thá»±c táº¿ trong lab

Vá»›i account ID cá»§a báº¡n:

```text
S3 Bucket: mlops-retail-prediction-dev-842676018087
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ transactions.csv                # file gá»‘c ~4.59GB
â”œâ”€â”€ silver/
â”‚   â”œâ”€â”€ transactions/                   # output tá»« Glue ETL (náº¿u khÃ´ng partition theo week)
â”‚   â””â”€â”€ shop_week=200607/
â”‚       â””â”€â”€ run-1761638745394-part-block-0-0-r-00000-snappy.parquet  # ~458MB
â”œâ”€â”€ gold/
â”‚   â””â”€â”€ (dÃ nh cho feature store / aggregated tables)
â””â”€â”€ artifacts/
    â””â”€â”€ (lÆ°u wyniki benchmark, model, logs,â€¦)
```

Báº¡n cÃ³ thá»ƒ má»Ÿ S3 Console Ä‘á»ƒ xÃ¡c nháº­n Ä‘Ãºng Ä‘Æ°á»ng dáº«n, nháº¥t lÃ :

- `raw/transactions.csv`
- Má»™t file Parquet tiÃªu biá»ƒu trong `silver/shop_week=.../`.

---

## 2. Táº¡o bucket & thÆ° má»¥c trÃªn AWS Console

### 2.1. Táº¡o S3 Bucket

1. VÃ o **AWS Console â†’ S3 â†’ Create bucket**.
2. Cáº¥u hÃ¬nh:

```text
Bucket name: mlops-retail-prediction-dev-842676018087
Region: us-east-1
Block all public access: âœ… Enabled
Versioning: (khuyáº¿n nghá»‹) Enabled
Default encryption: âœ… SSE-S3
```

_Minh há»a:_ `../images/s3-data-storage/01-create-bucket.png`

<!-- IMAGE PLACEHOLDER: Create-bucket - paste screenshot here -->

![Placeholder - Create bucket](../images/s3-data-storage/placeholder-create-bucket.png)

---

### 2.2. Táº¡o 4 thÆ° má»¥c chÃ­nh

Trong S3 Console:

1. Má»Ÿ bucket `mlops-retail-prediction-dev-842676018087`.
2. **Create folder** láº§n lÆ°á»£t:

```text
raw/
silver/
gold/
artifacts/
```

<!-- IMAGE PLACEHOLDER: Create-folders - paste screenshot here -->

![Placeholder - Create folders](../images/s3-data-storage/placeholder-folders.png)

---

## 3. Báº­t Intelligent-Tiering (tá»‘i Æ°u chi phÃ­)

Má»¥c Ä‘Ã­ch: dá»¯ liá»‡u Ã­t truy cáº­p (vÃ­ dá»¥ `raw/` cÅ©, `artifacts/` log cÅ©) Ä‘Æ°á»£c chuyá»ƒn tá»± Ä‘á»™ng sang lá»›p lÆ°u trá»¯ ráº» hÆ¡n, khÃ´ng Ä‘á»•i URL.

CÃ¡c bÆ°á»›c:

1. VÃ o bucket â†’ tab **Properties**.
2. TÃ¬m pháº§n **Intelligent-Tiering archive configurations** â†’ **Edit**.
3. ThÃªm cáº¥u hÃ¬nh:

```text
Configuration name: storage-optimization
Status: Enabled
Scope: Entire bucket (hoáº·c prefix cá»¥ thá»ƒ: raw/, silver/, gold/, artifacts/)
```

<!-- IMAGE PLACEHOLDER: Intelligent-tiering - paste screenshot here -->

![Placeholder - Intelligent Tiering](../images/s3-data-storage/placeholder-intelligent-tiering.png)

---

## 4. Chuyá»ƒn CSV â†’ Parquet báº±ng AWS Glue Studio (Visual ETL)

### 4.1. Upload `transactions.csv` vÃ o `raw/`

TrÃªn S3 Console:

1. Má»Ÿ bucket â†’ folder `raw/`.
2. **Upload â†’ Add files â†’** chá»n file `transactions.csv` trÃªn mÃ¡y.
3. **Upload**.

<!-- IMAGE PLACEHOLDER: Upload-csv - paste screenshot here -->

![Placeholder - Upload CSV](../images/s3-data-storage/placeholder-upload.png)

---

### 4.2. Táº¡o Glue Job (Visual ETL)

1. VÃ o **AWS Glue Studio â†’ Jobs â†’ Create job â†’ Visual with a blank canvas**.
2. Äáº·t tÃªn:

```text
Job name: csv-to-parquet-converter
```

3. Chá»n/ táº¡o IAM Role cÃ³ quyá»n:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": ["s3:GetObject", "s3:PutObject"],
      "Resource": [
        "arn:aws:s3:::mlops-retail-prediction-dev-842676018087/raw/*",
        "arn:aws:s3:::mlops-retail-prediction-dev-842676018087/silver/*"
      ]
    },
    {
      "Effect": "Allow",
      "Action": [
        "glue:*",
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents"
      ],
      "Resource": "*"
    }
  ]
}
```

---

### 4.3. Source node â€“ Ä‘á»c CSV tá»« S3

Trong canvas Glue Studio:

1. ThÃªm **S3 Source**.
2. Cáº¥u hÃ¬nh:

```text
Data source: S3
Format: CSV
S3 URL: s3://mlops-retail-prediction-dev-842676018087/raw/transactions.csv
First row as header: Enabled
Delimiter: ,
```

<!-- IMAGE PLACEHOLDER: Glue Source config - paste screenshot here -->

![Placeholder - Glue Source](../images/s3-data-storage/placeholder-glue-source.png)

TÃ³m táº¯t:

|     Field | Value                                      |
| --------: | ------------------------------------------ |
| S3 bucket | `mlops-retail-prediction-dev-842676018087` |
|      Path | `raw/transactions.csv`                     |
|    Format | CSV                                        |
|    Header | Yes                                        |
| Delimiter | `,`                                        |

---

### 4.4. Transform â€“ ApplyMapping (tá»‘i Æ°u schema)

1. ThÃªm node **ApplyMapping**.
2. Káº¿t ná»‘i **Source â†’ ApplyMapping**.
3. Mapping kiá»ƒu dá»¯ liá»‡u (vÃ­ dá»¥):

| Column      | Source type | Target type   | Ghi chÃº          |
| ----------- | ----------: | ------------- | ---------------- |
| SHOP_WEEK   |        long | int           | `int32` lÃ  Ä‘á»§    |
| SHOP_HOUR   |        long | tinyint       | 0â€“23             |
| QUANTITY    |        long | smallint      | Sá»‘ lÆ°á»£ng         |
| STORE_CODE  |      string | string        | Giá»¯ nguyÃªn       |
| SPEND       |     decimal | decimal(10,2) | Tiá»n tá»‡, 2 sá»‘ láº» |
| BASKET_TYPE |      string | string        | Categorical      |

<!-- IMAGE PLACEHOLDER: Transform schema - paste screenshot here -->

![Placeholder - Transform schema](../images/s3-data-storage/placeholder-transform.png)

**Lá»£i Ã­ch:**

- Giáº£m kÃ­ch thÆ°á»›c file Parquet.
- Tá»‘i Æ°u scan & aggregation.
- Giáº£m RAM khi Ä‘á»c dá»¯ liá»‡u.

---

### 4.5. Target â€“ ghi Parquet (Snappy) ra `silver/`

1. ThÃªm node **S3 Target**.
2. Káº¿t ná»‘i **ApplyMapping â†’ Target**.
3. Cáº¥u hÃ¬nh:

```text
Data target: S3
Format: Parquet
Compression: Snappy
S3 path: s3://mlops-retail-prediction-dev-842676018087/silver/transactions/
Partition keys: SHOP_WEEK (khuyáº¿n nghá»‹)
```

_Minh há»a:_

-- Target config: `../images/s3-data-storage/target-config.png`
-- ToÃ n pipeline: `../images/s3-data-storage/04-glue-etl.png`

<!-- IMAGE PLACEHOLDER: Glue Target / Pipeline - paste screenshot here -->

![Placeholder - Glue Target](../images/s3-data-storage/placeholder-glue-target.png)

4. **Save & Run job** â†’ theo dÃµi **Job run details** â†’ kiá»ƒm tra output trong `silver/`.

![Placeholder - Glue Target](../images/s3-data-storage/04-glue-etl.png)

![Placeholder - Glue Target](../images/s3-data-storage/result-in-silver.png)

---

## 5. Benchmark thá»±c táº¿ trÃªn AWS CloudShell (Ä‘á»c trá»±c tiáº¿p tá»« S3)

### 5.1. ThÃ´ng tin dataset & cÃ¡ch cháº¡y

- Cháº¡y trÃªn **AWS CloudShell**.
- Äá»c trá»±c tiáº¿p:

  - `raw/transactions.csv` (~4,593.65 MB, 33,850,823 rows).
  - 1 file Parquet (~458.45 MB, 33,850,823 rows).

Báº¡n Ä‘Ã£ dÃ¹ng script kiá»ƒu:

- `read_csv_s3(...)` Ä‘á»ƒ Ä‘o Ä‘á»c CSV.
- `read_parquet_s3(...)` Ä‘á»ƒ Ä‘o Ä‘á»c Parquet.

Log chi tiáº¿t Ä‘Ã£ hiá»‡n trong CloudShell.)

<!-- IMAGE PLACEHOLDER: CloudShell benchmark - paste screenshot here -->

Káº¿t quáº£ Ä‘o Ä‘á»c CSV:
![Placeholder - CloudShell benchmark](../images/s3-data-storage/placeholder-cloudshell.png)

Káº¿t quáº£ Ä‘o Ä‘á»c Parquet:
![Placeholder - CloudShell benchmark](../images/s3-data-storage/placeholder-cloudshell-parquet.png)

---

### 5.2. Káº¿t quáº£ Ä‘o (CloudShell)

**CSV â€“ Ä‘á»c toÃ n bá»™ `raw/transactions.csv` tá»« S3**

5 láº§n Ä‘o:

```text
151.91s, 146.34s, 141.52s, 126.03s, 115.95s
```

TÃ­nh trung bÃ¬nh (xáº¥p xá»‰):

- Avg time â‰ˆ **136.35 s**
- Size = **4,593.65 MB**
- Avg throughput â‰ˆ **33.7 MB/s**
- Rows/s â‰ˆ **~248k rows/s**

---

**Parquet â€“ Ä‘á»c 1 file ~458.45 MB tá»« S3**

5 láº§n Ä‘o:

```text
61.37s, 53.65s, 52.51s, 49.66s, 49.55s
```

TÃ­nh trung bÃ¬nh (xáº¥p xá»‰):

- Avg time â‰ˆ **53.35 s**
- Size = **458.45 MB**
- Avg throughput â‰ˆ **8.6 MB/s**
- Rows/s â‰ˆ **~635k rows/s**

---

### 5.3. Báº£ng so sÃ¡nh (CloudShell)

|    Loáº¡i | Size trÃªn S3 | Avg time (s) | Avg throughput (MB/s) |       Rows | Rows/s (xáº¥p xá»‰) | Relative rows/s |
| ------: | -----------: | -----------: | --------------------: | ---------: | --------------: | --------------: |
|     CSV |  4,593.65 MB |       136.35 |                  33.7 | 33,850,823 |           ~248k |              1Ã— |
| Parquet |    458.45 MB |        53.35 |                   8.6 | 33,850,823 |           ~635k |           ~2.6Ã— |

**Giáº£i thÃ­ch:**

- Theo **MB/s**, CSV cÃ³ váº» â€œnhanhâ€ hÆ¡n vÃ¬ má»—i run xá»­ lÃ½ nhiá»u MB hÆ¡n (4.59 GB).
- NhÆ°ng xÃ©t **sá»‘ dÃ²ng/giÃ¢y (rows/s)**, Parquet **nhanh hÆ¡n ~2.6Ã—**, phÃ¹ há»£p cho ETL / training.

{{% notice info %}}
**Káº¿t luáº­n CloudShell**

- Parquet (Snappy) **giáº£m máº¡nh dung lÆ°á»£ng**: 4.59 GB â†’ ~0.46 GB.
- Vá»›i cÃ¹ng 33.85M dÃ²ng, Parquet xá»­ lÃ½ **nhanh hÆ¡n ~2.6Ã—** vá» rows/s.
  {{% /notice %}}

---

## 6. Benchmark trÃªn mÃ¡y local (Windows, 16GB RAM)

### 6.1. Chuáº©n bá»‹ thÆ° má»¥c & táº£i dá»¯ liá»‡u

TrÃªn Windows:

```bash
mkdir s3-local-benchmark
cd s3-local-benchmark
```

Táº£i 2 file:

```bash
aws s3 cp s3://mlops-retail-prediction-dev-842676018087/raw/transactions.csv ./transactions.csv
aws s3 cp s3://mlops-retail-prediction-dev-842676018087/silver/shop_week=200607/run-1761638745394-part-block-0-0-r-00000-snappy.parquet ./transactions_200607.parquet



```

<!-- IMAGE PLACEHOLDER: Local download - paste screenshot here -->

## ![Placeholder - Local download](../images/s3-data-storage/placeholder-local-download.png)

### 6.2. Script benchmark

Táº¡o file `local_benchmark.py`:

```python
import time
import os
import pandas as pd

def bench_csv_stream(path: str, runs: int = 3):
    print(f"=== Benchmark CSV (streaming): {path} ===")
    size_mb = os.path.getsize(path) / (1024 * 1024)
    for i in range(1, runs + 1):
        t0 = time.time()
        rows = 0
        # Äá»c theo chunks Ä‘á»ƒ trÃ¡nh trÃ n RAM
        for chunk in pd.read_csv(path, chunksize=500_000):
            rows += len(chunk)
        t1 = time.time()
        elapsed = t1 - t0
        throughput = size_mb / elapsed
        print(f"[local_csv_stream] run={i} time={elapsed:.2f}s, "
              f"size={size_mb:.2f} MB, throughput={throughput:.2f} MB/s, rows={rows}")

def bench_parquet_stream(path: str, runs: int = 3):
    print(f"
=== Benchmark Parquet (streaming): {path} ===")
    size_mb = os.path.getsize(path) / (1024 * 1024)
    for i in range(1, runs + 1):
        t0 = time.time()
        df = pd.read_parquet(path)
        rows = len(df)
        t1 = time.time()
        elapsed = t1 - t0
        throughput = size_mb / elapsed
        print(f"[local_parquet_stream] run={i} time={elapsed:.2f}s, "
              f"size={size_mb:.2f} MB, throughput={throughput:.2f} MB/s, rows={rows}")

if __name__ == "__main__":
    bench_csv_stream("transactions.csv", runs=3)
    bench_parquet_stream("transactions_200607.parquet", runs=3)
```

Cháº¡y:

```bash
python local_benchmark.py
```

---

### 6.3. Log thá»±c táº¿

## ![Placeholder - Local download](../images/s3-data-storage/placeholder-result-readfile.png)

````

**Nháº­n xÃ©t:**

- CSV full 4.59 GB: váº«n xá»­ lÃ½ Ä‘Æ°á»£c nhá» Ä‘á»c theo chunks, throughput ~90â€“95 MB/s.
- Parquet (sample 1 tuáº§n, 6.48 MB): thá»i gian Ä‘á»c ~0.05â€“0.09s â†’ latency cá»±c tháº¥p.
- Vá»›i nhiá»u file Parquet nhá» (partition theo `shop_week`), query theo tuáº§n/thÃ¡ng sáº½ ráº¥t nhanh.

---

## 7. IAM â€“ Quyá»n tá»‘i thiá»ƒu cho Glue Job (tÃ³m táº¯t)

Tá»‘i thiá»ƒu cáº§n:

- **S3:**
  - `s3:GetObject` cho `raw/*`
  - `s3:PutObject` cho `silver/*`
- **Glue:**
  - Quyá»n táº¡o/cháº¡y job, Ä‘á»c metadata (tÃ¹y mÃ´i trÆ°á»ng).
- **CloudWatch Logs:** ghi log job.

VÃ­ dá»¥ policy:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": ["s3:GetObject", "s3:PutObject"],
      "Resource": [
        "arn:aws:s3:::mlops-retail-prediction-dev-842676018087/raw/*",
        "arn:aws:s3:::mlops-retail-prediction-dev-842676018087/silver/*"
      ]
    },
    {
      "Effect": "Allow",
      "Action": [
        "glue:*",
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents"
      ],
      "Resource": "*"
    }
  ]
}
````

---

## 8. Tá»•ng káº¿t Task 3 â€“ S3 Data Storage

**Vá» kiáº¿n trÃºc:**

- Thiáº¿t káº¿ bucket theo chuáº©n MLOps:

  ```text
  raw/ â†’ silver/ â†’ gold/ â†’ artifacts/
  ```

- Duy trÃ¬ **raw/ immutable**.
- Chuáº©n hÃ³a dá»¯ liá»‡u vÃ o **Parquet (Snappy)** trong **silver/**.

**Vá» hiá»‡u nÄƒng (tá»« sá»‘ Ä‘o thá»±c táº¿ cá»§a báº¡n):**

- 4.59 GB CSV â†’ ~0.46 GB Parquet cho cÃ¹ng **33.85M dÃ²ng**.
- TrÃªn CloudShell:

  - CSV: ~136s, ~248k rows/s.
  - Parquet: ~53s, ~635k rows/s â†’ **~2.6Ã— rows/s**.

- TrÃªn mÃ¡y local (16GB RAM):

  - CSV 4.59 GB váº«n xá»­ lÃ½ Ä‘Æ°á»£c vá»›i **chunk 500k rows**.
  - Parquet sample 1 tuáº§n (~6.48 MB) Ä‘á»c trong **~0.05â€“0.09s**.

**Vá» cost & váº­n hÃ nh:**

- Parquet + Snappy **giáº£m Ä‘Ã¡ng ká»ƒ dung lÆ°á»£ng** â†’ giáº£m tiá»n S3.
- Intelligent-Tiering giÃºp tá»± Ä‘á»™ng háº¡ táº§ng lá»›p lÆ°u trá»¯ cho dá»¯ liá»‡u cÅ©.
- Glue Visual ETL giÃºp khÃ´ng cáº§n code nhiá»u, dá»… show trong bÃ¡o cÃ¡o.

{{% notice success %}}
**ğŸ¯ Task 3 hoÃ n thÃ nh**

- Kiáº¿n trÃºc S3 rÃµ rÃ ng, chuáº©n MLOps.
- CSV â†’ Parquet báº±ng Glue Studio (Visual, cÃ³ hÃ¬nh minh há»a).
- CÃ³ benchmark thá»±c táº¿ trÃªn **CloudShell** vÃ  **local**, cÃ³ sá»‘ liá»‡u cá»¥ thá»ƒ.
- Dá»… trÃ¬nh bÃ y trong bÃ¡o cÃ¡o & demo cho GV.
  {{% /notice %}}
