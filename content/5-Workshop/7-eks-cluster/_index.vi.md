---
title: "EKS Cluster Setup"
weight: 7
chapter: false
pre: "<b>7. </b>"
---

## üéØ M·ª•c ti√™u Task 7

Tri·ªÉn khai Amazon Elastic Kubernetes Service (EKS) ƒë·ªÉ l√†m n·ªÅn t·∫£ng ch·∫°y API d·ª± ƒëo√°n (FastAPI) trong m√¥i tr∆∞·ªùng production:

1. **EKS Control Plane**: Cluster qu·∫£n l√Ω b·ªüi AWS v·ªõi Kubernetes 1.30
2. **IRSA Integration**: IAM Roles for Service Accounts cho secure AWS access
3. **Cost Optimization**: Free Tier t2.micro instances cho development
4. **VPC Integration**: S·ª≠ d·ª•ng hybrid VPC v√† VPC Endpoints t·ª´ Task 5
5. **ECR Integration**: Container image pulls t·ª´ ECR repository

‚Üí ƒê·∫£m b·∫£o h·ªá th·ªëng ·ªïn ƒë·ªãnh, m·ªü r·ªông linh ho·∫°t (scalable), v√† t√≠ch h·ª£p b·∫£o m·∫≠t v·ªõi IAM (IRSA).

üì• **Input t·ª´ c√°c Task tr∆∞·ªõc:**
- **Task 5 (Production VPC):** Hybrid VPC, subnets, VPC Endpoints and security groups used for EKS networking
- **Task 2 (IAM Roles & Audit):** IAM roles and policies (cluster role, node role, IRSA foundations)
- **Task 6 (ECR Registry):** ECR repository for container images that EKS will pull

## Ki·∫øn tr√∫c EKS trong MLOps Pipeline

{{% notice tip %}}
**Tip:** S·ª≠ d·ª•ng private-only endpoint access cho production clusters v√† gi·ªõi h·∫°n public access CIDRs theo IP ranges c·ª• th·ªÉ. B·∫≠t t·∫•t c·∫£ control plane logs ƒë·ªÉ audit b·∫£o m·∫≠t v√† tu√¢n th·ªß quy ƒë·ªãnh.
{{% /notice %}}

### Cost Optimization Strategy

| Component               | Cost           | Free Tier     | Strategy                    |
| ----------------------- | -------------- | ------------- | --------------------------- |
| **EKS Control Plane**   | $73/month      | ‚ùå            | Use for demo, destroy after |
| **t2.micro Nodes (2x)** | **$0**         | ‚úÖ 750h/month | 12 months FREE              |
| **EBS Storage (20GB)**  | **$0**         | ‚úÖ 30GB FREE  | Within free tier            |
| **VPC Endpoints**       | $21.6/month    | ‚ùå            | Shared with other services  |
| **Total**               | **~$95/month** |               | **$60/month savings**       |

**Free Tier Benefits:**

- **750 hours/month** t2.micro instances ‚Üí Enough for 24/7 demo
- **30GB EBS storage** ‚Üí Adequate for basic workloads
- **Total savings**: $60/month vs t3.medium instances

{{% notice warning %}}
**Warning:** EKS control plane t·ªën $73/th√°ng b·∫•t k·ªÉ m·ª©c s·ª≠ d·ª•ng. ƒê·ªÉ h·ªçc t·∫≠p/testing, c√¢n nh·∫Øc d√πng self-managed k3s tr√™n EC2 ho·∫∑c kind locally ƒë·ªÉ tr√°nh chi ph√≠ c·ªë ƒë·ªãnh. X√≥a cluster ngay sau khi demo.
{{% /notice %}}

## 1. EKS Cluster Setup via Console

### 1.1. Create EKS Cluster

1. **Navigate to EKS Console:**

   - AWS Console ‚Üí EKS ‚Üí "Create cluster"

2. **Basic Configuration:**

   ```
   Cluster name: mlops-retail-cluster
   Kubernetes version: 1.30
   Cluster service role: Use existing from Task 2 (IAM)
   ```

3. **Networking Configuration:**
   ```
   VPC: mlops-retail-forecast-hybrid-vpc (from Task 5)
   Subnets: Select all 4 subnets (2 public + 2 private)
   Cluster endpoint access: Public and private
   Public access sources: Specify your IP range
   Security groups: mlops-hybrid-eks-control-plane-sg
   ```

![EKS Console Configuration](../images/07-eks-cluster/02-eks-console-config.png)

4. **Control Plane Logging:**
   ```
   ‚úÖ API server
   ‚úÖ Audit
   ‚úÖ Authenticator
   ‚úÖ Controller manager
   ‚úÖ Scheduler
   ```

![Control Plane Logging Settings](../images/07-eks-cluster/03-control-plane-logging.png)

5. **Add-ons Configuration:**
   ```
   ‚úÖ Amazon VPC CNI: v1.18.1-eksbuild.1
   ‚úÖ CoreDNS: v1.11.1-eksbuild.4
   ‚úÖ kube-proxy: v1.30.0-eksbuild.3
   ‚úÖ Amazon EBS CSI Driver: v1.30.0-eksbuild.1
   ```

![Add-ons Configuration](../images/07-eks-cluster/04-addons-configuration.png)

### 1.2. Update kubeconfig

```bash
# Configure kubectl for new cluster
aws eks update-kubeconfig --region ap-southeast-1 --name mlops-retail-cluster

# Verify connection
kubectl get svc
kubectl cluster-info
```

**Expected output:**

```
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   172.20.0.1   <none>        443/TCP   5m

Kubernetes control plane is running at https://ABC123.gr7.ap-southeast-1.eks.amazonaws.com
CoreDNS is running at https://ABC123.gr7.ap-southeast-1.eks.amazonaws.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
```

![kubeconfig Verification](../images/07-eks-cluster/05-kubeconfig-verification.png)

### 1.3. Verify Add-ons

```bash
# Check core add-ons
kubectl get pods -n kube-system

# Verify VPC CNI
kubectl get daemonset -n kube-system aws-node

# Check CoreDNS
kubectl get deployment -n kube-system coredns

# Verify kube-proxy
kubectl get daemonset -n kube-system kube-proxy

# Check EBS CSI driver
kubectl get deployment -n kube-system ebs-csi-controller
```

![Add-ons Status Verification](../images/07-eks-cluster/06-addons-verification.png)

{{% notice success %}}
**üéØ EKS Control Plane Ready!**

**Control Plane Status:**

- ‚úÖ Kubernetes 1.30 cluster ACTIVE
- ‚úÖ Multi-AZ managed control plane
- ‚úÖ All essential add-ons running
- ‚úÖ CloudWatch logging enabled
- ‚úÖ kubectl access configured
  {{% /notice %}}

{{% notice info %}}
**Info:** EKS control plane t·ª± ƒë·ªông ch·∫°y tr√™n nhi·ªÅu AZs. ƒê·ªÉ t·ªëi ∆∞u chi ph√≠, ƒë·∫£m b·∫£o worker nodes c√¢n b·∫±ng gi·ªØa c√°c AZs ƒë·ªÉ tr√°nh ph√≠ cross-AZ data transfer ($0.01/GB).
{{% /notice %}}

## 2. IRSA (IAM Roles for Service Accounts) Setup

### 2.1. Associate OIDC Provider

```bash
# Check if OIDC provider exists
aws eks describe-cluster --name mlops-retail-cluster \
    --region ap-southeast-1 \
    --query "cluster.identity.oidc.issuer" --output text

# Associate OIDC identity provider with cluster
eksctl utils associate-iam-oidc-provider \
    --cluster mlops-retail-cluster \
    --region ap-southeast-1 \
    --approve
```

**Expected output:**

```
‚úÖ Created OIDC identity provider for cluster "mlops-retail-cluster" in region "ap-southeast-1"
```

![OIDC Provider Setup](../images/07-eks-cluster/07-oidc-provider-setup.png)

### 2.2. Create IRSA Role for S3 Access

**Create file `scripts/create-irsa-s3-role.sh`:**

```bash
#!/bin/bash

# Configuration
CLUSTER_NAME="mlops-retail-cluster"
REGION="ap-southeast-1"
NAMESPACE="mlops-retail-forecast"
SERVICE_ACCOUNT="s3-access-sa"
ROLE_NAME="mlops-irsa-s3-access-role"
POLICY_NAME="mlops-irsa-s3-policy"

# Get OIDC issuer URL
OIDC_ISSUER=$(aws eks describe-cluster \
    --name $CLUSTER_NAME \
    --region $REGION \
    --query "cluster.identity.oidc.issuer" \
    --output text | sed 's|https://||')

# Get AWS account ID
ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

echo "üîß Creating IRSA role for S3 access..."
echo "Cluster: $CLUSTER_NAME"
echo "OIDC Issuer: $OIDC_ISSUER"
echo "Namespace: $NAMESPACE"
echo "Service Account: $SERVICE_ACCOUNT"

# Create trust policy
cat > trust-policy.json << EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Federated": "arn:aws:iam::${ACCOUNT_ID}:oidc-provider/${OIDC_ISSUER}"
      },
      "Action": "sts:AssumeRoleWithWebIdentity",
      "Condition": {
        "StringEquals": {
          "${OIDC_ISSUER}:sub": "system:serviceaccount:${NAMESPACE}:${SERVICE_ACCOUNT}",
          "${OIDC_ISSUER}:aud": "sts.amazonaws.com"
        }
      }
    }
  ]
}
EOF

# Create IAM role
aws iam create-role \
    --role-name $ROLE_NAME \
    --assume-role-policy-document file://trust-policy.json \
    --description "IRSA role for EKS pods to access S3"

# Create S3 access policy
cat > s3-policy.json << EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:PutObject",
        "s3:DeleteObject",
        "s3:ListBucket",
        "s3:GetBucketLocation"
      ],
      "Resource": [
        "arn:aws:s3:::mlops-retail-forecast-models",
        "arn:aws:s3:::mlops-retail-forecast-models/*",
        "arn:aws:s3:::mlops-retail-forecast-data",
        "arn:aws:s3:::mlops-retail-forecast-data/*"
      ]
    }
  ]
}
EOF

# Create and attach policy
aws iam create-policy \
    --policy-name $POLICY_NAME \
    --policy-document file://s3-policy.json \
    --description "S3 access policy for ML workloads"

aws iam attach-role-policy \
    --role-name $ROLE_NAME \
    --policy-arn arn:aws:iam::${ACCOUNT_ID}:policy/${POLICY_NAME}

# Clean up temp files
rm trust-policy.json s3-policy.json

echo "‚úÖ IRSA S3 role created successfully!"
echo "Role ARN: arn:aws:iam::${ACCOUNT_ID}:role/${ROLE_NAME}"
```

**Run the script:**

```bash
chmod +x scripts/create-irsa-s3-role.sh
./scripts/create-irsa-s3-role.sh
```

### 2.3. Create IRSA Role for CloudWatch

**Create file `scripts/create-irsa-cloudwatch-role.sh`:**

```bash
#!/bin/bash

# Configuration
CLUSTER_NAME="mlops-retail-cluster"
REGION="ap-southeast-1"
NAMESPACE="mlops-retail-forecast"
SERVICE_ACCOUNT="cloudwatch-sa"
ROLE_NAME="mlops-irsa-cloudwatch-role"

# Get OIDC issuer and account ID
OIDC_ISSUER=$(aws eks describe-cluster \
    --name $CLUSTER_NAME \
    --region $REGION \
    --query "cluster.identity.oidc.issuer" \
    --output text | sed 's|https://||')

ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

echo "üîß Creating IRSA role for CloudWatch access..."

# Create trust policy for CloudWatch service account
cat > cloudwatch-trust-policy.json << EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Federated": "arn:aws:iam::${ACCOUNT_ID}:oidc-provider/${OIDC_ISSUER}"
      },
      "Action": "sts:AssumeRoleWithWebIdentity",
      "Condition": {
        "StringEquals": {
          "${OIDC_ISSUER}:sub": "system:serviceaccount:${NAMESPACE}:${SERVICE_ACCOUNT}",
          "${OIDC_ISSUER}:aud": "sts.amazonaws.com"
        }
      }
    }
  ]
}
EOF

# Create IAM role
aws iam create-role \
    --role-name $ROLE_NAME \
    --assume-role-policy-document file://cloudwatch-trust-policy.json \
    --description "IRSA role for EKS pods to access CloudWatch"

# Attach CloudWatch agent policy
aws iam attach-role-policy \
    --role-name $ROLE_NAME \
    --policy-arn arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy

# Clean up
rm cloudwatch-trust-policy.json

echo "‚úÖ IRSA CloudWatch role created successfully!"
echo "Role ARN: arn:aws:iam::${ACCOUNT_ID}:role/${ROLE_NAME}"
```

**Run the script:**

```bash
chmod +x scripts/create-irsa-cloudwatch-role.sh
./scripts/create-irsa-cloudwatch-role.sh
```

### 2.4. Create Kubernetes Service Accounts

**Create file `k8s/service-accounts.yaml`:**

```yaml
---
apiVersion: v1
kind: Namespace
metadata:
  name: mlops-retail-forecast
  labels:
    name: mlops-retail-forecast
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: s3-access-sa
  namespace: mlops-retail-forecast
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT_ID:role/mlops-irsa-s3-access-role
  labels:
    app.kubernetes.io/name: s3-access-service-account
    app.kubernetes.io/component: rbac
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: cloudwatch-sa
  namespace: mlops-retail-forecast
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT_ID:role/mlops-irsa-cloudwatch-role
  labels:
    app.kubernetes.io/name: cloudwatch-service-account
    app.kubernetes.io/component: monitoring
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: retail-api-sa
  namespace: mlops-retail-forecast
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT_ID:role/mlops-irsa-s3-access-role
  labels:
    app.kubernetes.io/name: retail-api-service-account
    app.kubernetes.io/component: api
```

**Apply service accounts:**

```bash
# Replace ACCOUNT_ID with your AWS account ID
ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
sed "s/ACCOUNT_ID/$ACCOUNT_ID/g" k8s/service-accounts.yaml | kubectl apply -f -

# Verify service accounts
kubectl get serviceaccounts -n mlops-retail-forecast
kubectl describe serviceaccount s3-access-sa -n mlops-retail-forecast
```

{{% notice success %}}
**üéØ IRSA Setup Complete!**

**IRSA Components:**

- ‚úÖ OIDC identity provider associated with EKS
- ‚úÖ S3 access role for ML workloads
- ‚úÖ CloudWatch role for monitoring
- ‚úÖ Kubernetes service accounts with proper annotations
- ‚úÖ Secure AWS access without hardcoded credentials
  {{% /notice %}}

{{% notice tip %}}
**Tip:** S·ª≠ d·ª•ng service accounts ri√™ng bi·ªát cho t·ª´ng workload v·ªõi minimal IAM policies. Tr√°nh chia s·∫ª service accounts gi·ªØa c√°c ·ª©ng d·ª•ng v√† th∆∞·ªùng xuy√™n audit IRSA role permissions.
{{% /notice %}}

## 3. Managed Node Group Setup

### 3.1. Create Node Group via Console

1. **Navigate to Node Groups:**

   - EKS Console ‚Üí mlops-retail-cluster ‚Üí Compute ‚Üí Node groups ‚Üí "Add node group"

2. **Node Group Configuration:**

   ```
   Name: mlops-retail-nodegroup-t2micro
   Node IAM role: mlops-hybrid-eks-nodes-role (from Task 5)
   ```

3. **Instance Configuration:**

   ```
   AMI type: Amazon Linux 2 (AL2_x86_64)
   Capacity type: On-Demand
   Instance types: t2.micro
   Disk size: 20 GB
   ```

4. **Scaling Configuration:**

   ```
   Desired size: 2
   Minimum size: 1
   Maximum size: 4
   ```

5. **Network Configuration:**
   ```
   Subnets: Both private workload subnets
   Configure remote access: Enable (optional)
   SSH key pair: Your EC2 key pair (optional)
   Source security groups: mlops-hybrid-eks-nodes-sg
   ```

![Node Group Console Configuration](../images/07-eks-cluster/08-nodegroup-console-config.png)

### 3.2. Alternative: eksctl Node Group (Command Line)

**Create file `scripts/create-nodegroup.sh`:**

```bash
#!/bin/bash

# Configuration
CLUSTER_NAME="mlops-retail-cluster"
REGION="ap-southeast-1"
NODEGROUP_NAME="mlops-retail-nodegroup-t2micro"

echo "üîß Creating EKS node group with t2.micro instances..."

# Create node group using eksctl
eksctl create nodegroup \
    --cluster=$CLUSTER_NAME \
    --region=$REGION \
    --name=$NODEGROUP_NAME \
    --node-type=t2.micro \
    --nodes=2 \
    --nodes-min=1 \
    --nodes-max=4 \
    --node-volume-size=20 \
    --node-volume-type=gp3 \
    --ssh-access \
    --ssh-public-key=YOUR_KEY_NAME \
    --managed \
    --node-private-networking \
    --node-zones=ap-southeast-1a,ap-southeast-1b

echo "‚úÖ Node group creation initiated!"
echo "Check status: eksctl get nodegroup --cluster $CLUSTER_NAME --region $REGION"
```

### 3.3. Verify Node Group

```bash
# Check node group status
aws eks describe-nodegroup \
    --cluster-name mlops-retail-cluster \
    --nodegroup-name mlops-retail-nodegroup-t2micro \
    --region ap-southeast-1

# Verify nodes in Kubernetes
kubectl get nodes
kubectl get nodes -o wide

# Check node labels and annotations
kubectl describe nodes
```

**Expected output:**

```
NAME                                              STATUS   ROLES    AGE   VERSION
ip-10-0-101-123.ap-southeast-1.compute.internal   Ready    <none>   5m    v1.30.0-eks-xyz
ip-10-0-102-456.ap-southeast-1.compute.internal   Ready    <none>   5m    v1.30.0-eks-xyz
```

![Nodes Ready Status](../images/07-eks-cluster/11-nodes-ready-status.png)

{{% notice success %}}
**üéØ Node Group Ready!**

**Node Group Status:**

- ‚úÖ 2x t2.micro instances (Free Tier)
- ‚úÖ Private subnet deployment
- ‚úÖ Auto Scaling Group configured (1-4 instances)
- ‚úÖ All nodes in Ready state
- ‚úÖ EKS optimized AMI with latest patches
  {{% /notice %}}

{{% notice warning %}}
**Warning (t2.micro):** Gi·ªõi h·∫°n 1 vCPU v√† 1GB RAM. Theo d√µi CPU credits v√† c√¢n nh·∫Øc gi·ªõi h·∫°n burstable performance. Cho production ML workloads, s·ª≠ d·ª•ng t3.medium+ instances.
{{% /notice %}}

## 4. Cost Optimization with VPC Endpoints

### 4.1. Review VPC Endpoints for EKS

**VPC Endpoints Created in Task 5:**

```bash
# Verify VPC endpoints exist for EKS cost optimization
aws ec2 describe-vpc-endpoints \
    --filters "Name=vpc-id,Values=vpc-xxxxx" \
    --query 'VpcEndpoints[?ServiceName==`com.amazonaws.ap-southeast-1.s3`]'

aws ec2 describe-vpc-endpoints \
    --filters "Name=vpc-id,Values=vpc-xxxxx" \
    --query 'VpcEndpoints[?ServiceName==`com.amazonaws.ap-southeast-1.ecr.api`]'
```

**Expected VPC Endpoints:**

- ‚úÖ S3 Gateway Endpoint (FREE - no data charges)
- ‚úÖ ECR API Endpoint ($0.01/hour per AZ)
- ‚úÖ ECR Docker Endpoint ($0.01/hour per AZ)
- ‚úÖ CloudWatch Logs Endpoint ($0.01/hour per AZ)

### 4.2. Cost Savings with VPC Endpoints

| Data Transfer  | Without VPC Endpoints  | With VPC Endpoints     | Savings  |
| -------------- | ---------------------- | ---------------------- | -------- |
| **S3 Access**  | $0.09/GB (NAT Gateway) | **$0.00/GB** (Gateway) | **100%** |
| **ECR Pull**   | $0.09/GB (Internet)    | **$0.00/GB** (Private) | **100%** |
| **CloudWatch** | $0.09/GB (NAT Gateway) | **$0.00/GB** (Private) | **100%** |

{{% notice success %}}
**üí∞ Monthly Cost Breakdown v·ªõi t2.micro + VPC Endpoints:**

**EKS Control Plane:** $73.00/month (fixed)  
**t2.micro Nodes:** $0.00/month (FREE tier - 750 hours)  
**VPC Endpoints:** ~$7.20/month (4 endpoints √ó 2 AZ √ó $0.01/hour)  
**Data Transfer:** $0.00/month (all private via VPC endpoints)

**Total Monthly Cost:** ~$80.20/month  
**Savings vs NAT Gateway:** ~$45/month (NAT Gateway cost)
{{% /notice %}}

{{% notice info %}}
**Info:** VPC Endpoints lo·∫°i b·ªè internet routing cho AWS services nh∆∞ng t·ªën $0.01/gi·ªù per endpoint per AZ. Theo d√µi usage patterns v√† consolidate endpoints khi c√≥ th·ªÉ.
{{% /notice %}}

## 5. Deploy Sample Application with IRSA

### 5.1. Deploy FastAPI Prediction Service

**Create file `k8s/retail-api-deployment.yaml`:**

```yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: retail-api
  namespace: mlops-retail-forecast
  labels:
    app: retail-api
spec:
  replicas: 2
  selector:
    matchLabels:
      app: retail-api
  template:
    metadata:
      labels:
        app: retail-api
    spec:
      serviceAccountName: retail-api-sa # IRSA Service Account
      containers:
        - name: retail-api
          image: ACCOUNT_ID.dkr.ecr.ap-southeast-1.amazonaws.com/mlops/retail-api:latest
          ports:
            - containerPort: 8000
              name: http
          env:
            - name: AWS_DEFAULT_REGION
              value: "ap-southeast-1"
            - name: S3_BUCKET_MODELS
              value: "mlops-retail-forecast-models"
            - name: S3_BUCKET_DATA
              value: "mlops-retail-forecast-data"
          resources:
            requests:
              memory: "256Mi"
              cpu: "250m"
            limits:
              memory: "512Mi"
              cpu: "500m"
          readinessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 30
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 60
            periodSeconds: 20
---
apiVersion: v1
kind: Service
metadata:
  name: retail-api-service
  namespace: mlops-retail-forecast
  labels:
    app: retail-api
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: 8000
      name: http
  selector:
    app: retail-api
```

### 5.2. Deploy Application with IRSA

```bash
# Replace ACCOUNT_ID in deployment file
ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
sed "s/ACCOUNT_ID/$ACCOUNT_ID/g" k8s/retail-api-deployment.yaml | kubectl apply -f -

# Verify deployment
kubectl get deployments -n mlops-retail-forecast
kubectl get pods -n mlops-retail-forecast
kubectl get services -n mlops-retail-forecast

# Check logs to verify IRSA working
kubectl logs -l app=retail-api -n mlops-retail-forecast
```

### 5.3. Test IRSA S3 Access

**Create test pod:**

```bash
# Create test pod to verify IRSA S3 access
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: test-irsa-s3
  namespace: mlops-retail-forecast
spec:
  serviceAccountName: s3-access-sa
  containers:
  - name: test-s3
    image: amazon/aws-cli:latest
    command: ["/bin/sh"]
    args: ["-c", "aws s3 ls s3://mlops-retail-forecast-models && sleep 3600"]
    env:
    - name: AWS_DEFAULT_REGION
      value: "ap-southeast-1"
  restartPolicy: Never
EOF

# Check if S3 access works via IRSA
kubectl logs test-irsa-s3 -n mlops-retail-forecast
```

**Expected output:**

```
2024-01-15 10:30:45    model-v1.0.pkl
2024-01-15 10:31:20    model-v1.1.pkl
                           PRE training-data/
```

## 6. Cluster Verification

### 6.1. Control Plane Health Check

```bash
# Check cluster status
kubectl get --raw='/readyz?verbose'

# Check API server health
kubectl get --raw='/healthz'

# View cluster events
kubectl get events --sort-by=.metadata.creationTimestamp
```

### 6.2. Add-ons Verification

```bash
# Check CoreDNS
kubectl get pods -n kube-system -l k8s-app=kube-dns

# Check kube-proxy
kubectl get daemonset -n kube-system kube-proxy

# Check VPC CNI
kubectl get daemonset -n kube-system aws-node

# Check EBS CSI driver
kubectl get deployment -n kube-system ebs-csi-controller
```

### 6.3. RBAC and Permissions

```bash
# Check current user permissions
kubectl auth can-i "*" "*"

# List available API resources
kubectl api-resources

# Check cluster roles
kubectl get clusterroles | grep eks
```

### 6.4. IRSA Verification

```bash
# Deploy service accounts v·ªõi IRSA annotations
kubectl apply -f aws/k8s/service-accounts.yaml

# Deploy test pod v·ªõi IRSA authentication
kubectl apply -f aws/k8s/test-pod-irsa.yaml

# Verify pod c√≥ th·ªÉ access S3 qua IRSA (no AWS credentials needed!)
kubectl exec -it test-irsa-s3-access -- aws s3 ls

# Check IRSA role annotations
kubectl get serviceaccount s3-access-sa -o yaml

# Verify OIDC provider
aws iam list-open-id-connect-providers

# List IRSA roles
aws iam list-roles --query 'Roles[?contains(RoleName, `irsa`)].{RoleName:RoleName,CreateDate:CreateDate}'

# Test CloudWatch access
kubectl exec -it test-irsa-s3-access -- aws cloudwatch list-metrics --namespace "MLOps/RetailForecast"

# Cleanup test pod
kubectl delete pod test-irsa-s3-access
```

## 7. Monitoring v√† Logging

### 7.1. CloudWatch Integration

```bash
# Check if cluster logging is enabled
aws eks describe-cluster \
  --name mlops-retail-forecast-dev-cluster \
  --query 'cluster.logging'

# View control plane logs in CloudWatch
aws logs describe-log-groups \
  --log-group-name-prefix /aws/eks/mlops-retail-forecast-dev-cluster
```


### 7.2. Setup CloudWatch Container Insights

**File: `aws/k8s/cloudwatch-insights.yaml`**

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: amazon-cloudwatch
  labels:
    name: amazon-cloudwatch
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: cloudwatch-agent
  namespace: amazon-cloudwatch
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT_ID:role/mlops-retail-forecast-dev-irsa-cloudwatch
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: cloudwatch-agent
  namespace: amazon-cloudwatch
spec:
  selector:
    matchLabels:
      name: cloudwatch-agent
  template:
    metadata:
      labels:
        name: cloudwatch-agent
    spec:
      serviceAccountName: cloudwatch-agent
      containers:
        - name: cloudwatch-agent
          image: amazon/cloudwatch-agent:1.300026.2b251814
          env:
            - name: AWS_REGION
              value: ap-southeast-1
            - name: CLUSTER_NAME
              value: mlops-retail-forecast-dev-cluster
          volumeMounts:
            - name: cwagentconfig
              mountPath: /etc/cwagentconfig
            - name: rootfs
              mountPath: /rootfs
              readOnly: true
            - name: dockersock
              mountPath: /var/run/docker.sock
              readOnly: true
            - name: varlibdocker
              mountPath: /var/lib/docker
              readOnly: true
      volumes:
        - name: cwagentconfig
          configMap:
            name: cwagentconfig
        - name: rootfs
          hostPath:
            path: /
        - name: dockersock
          hostPath:
            path: /var/run/docker.sock
        - name: varlibdocker
          hostPath:
            path: /var/lib/docker
```

## 8. Security Hardening

### 8.1. Network Security

```bash
# Verify security groups
aws ec2 describe-security-groups \
  --group-ids $(terraform output -raw eks_control_plane_security_group_id) \
  --query 'SecurityGroups[0].{GroupId:GroupId,IpPermissions:IpPermissions}'

# Check VPC configuration
aws eks describe-cluster \
  --name mlops-retail-forecast-dev-cluster \
  --query 'cluster.resourcesVpcConfig'
```

### 8.2. RBAC Configuration

**File: `aws/k8s/rbac.yaml`**

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: mlops-admin
  namespace: mlops-retail-forecast
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: mlops-retail-forecast
  name: mlops-admin-role
rules:
  - apiGroups: [""]
    resources: ["pods", "services", "configmaps", "secrets"]
    verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
  - apiGroups: ["apps"]
    resources: ["deployments", "replicasets"]
    verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: mlops-admin-binding
  namespace: mlops-retail-forecast
subjects:
  - kind: ServiceAccount
    name: mlops-admin
    namespace: mlops-retail-forecast
roleRef:
  kind: Role
  name: mlops-admin-role
  apiGroup: rbac.authorization.k8s.io
```

## 9. D·ªçn d·∫πp Resources (AWS CLI)

### 9.1. X√≥a Node Groups

```bash
# List all node groups
aws eks list-nodegroups --cluster-name mlops-retail-cluster --region ap-southeast-1

# Delete node group (this will take 5-10 minutes)
aws eks delete-nodegroup \
    --cluster-name mlops-retail-cluster \
    --nodegroup-name mlops-retail-nodegroup-t2micro \
    --region ap-southeast-1

# Monitor deletion status
aws eks describe-nodegroup \
    --cluster-name mlops-retail-cluster \
    --nodegroup-name mlops-retail-nodegroup-t2micro \
    --region ap-southeast-1 \
    --query 'nodegroup.status'
```

### 9.2. X√≥a IRSA Roles v√† OIDC Provider

```bash
# Get account ID
ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

# Detach and delete S3 access role
aws iam detach-role-policy \
    --role-name mlops-irsa-s3-access-role \
    --policy-arn arn:aws:iam::${ACCOUNT_ID}:policy/mlops-irsa-s3-policy

aws iam delete-policy --policy-arn arn:aws:iam::${ACCOUNT_ID}:policy/mlops-irsa-s3-policy
aws iam delete-role --role-name mlops-irsa-s3-access-role

# Delete CloudWatch access role
aws iam detach-role-policy \
    --role-name mlops-irsa-cloudwatch-role \
    --policy-arn arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy

aws iam delete-role --role-name mlops-irsa-cloudwatch-role

# Delete OIDC provider
OIDC_URL=$(aws eks describe-cluster --name mlops-retail-cluster --region ap-southeast-1 --query 'cluster.identity.oidc.issuer' --output text | sed 's|https://||')
aws iam delete-open-id-connect-provider --open-id-connect-provider-arn arn:aws:iam::${ACCOUNT_ID}:oidc-provider/${OIDC_URL}
```

### 9.3. X√≥a EKS Cluster

```bash
# Delete the cluster (ensure node groups are deleted first)
aws eks delete-cluster --name mlops-retail-cluster --region ap-southeast-1

# Monitor deletion progress
aws eks describe-cluster --name mlops-retail-cluster --region ap-southeast-1 --query 'cluster.status'

# Verify cluster is deleted (should return error)
aws eks list-clusters --region ap-southeast-1 --query 'clusters[?contains(@, `mlops-retail-cluster`)]'
```

### 9.4. D·ªçn d·∫πp Kubernetes Resources

```bash
# Delete namespace (this removes all resources in the namespace)
kubectl delete namespace mlops-retail-forecast

# Remove cluster from kubeconfig
kubectl config delete-cluster arn:aws:eks:ap-southeast-1:${ACCOUNT_ID}:cluster/mlops-retail-cluster
kubectl config delete-context arn:aws:eks:ap-southeast-1:${ACCOUNT_ID}:cluster/mlops-retail-cluster

# Remove user from kubeconfig
kubectl config unset users.arn:aws:eks:ap-southeast-1:${ACCOUNT_ID}:cluster/mlops-retail-cluster
```

### 9.5. Script D·ªçn d·∫πp EKS T·ª± ƒë·ªông

```bash
#!/bin/bash
# eks-cleanup.sh

CLUSTER_NAME="mlops-retail-cluster"
REGION="ap-southeast-1"
NODEGROUP_NAME="mlops-retail-nodegroup-t2micro"

echo "üßπ Starting EKS cluster cleanup..."

# 1. Delete applications and namespace
echo "Deleting Kubernetes resources..."
kubectl delete namespace mlops-retail-forecast --ignore-not-found=true

# 2. Delete node group
echo "Deleting node group..."
aws eks delete-nodegroup \
    --cluster-name $CLUSTER_NAME \
    --nodegroup-name $NODEGROUP_NAME \
    --region $REGION

# Wait for node group deletion
echo "Waiting for node group deletion..."
aws eks wait nodegroup-deleted \
    --cluster-name $CLUSTER_NAME \
    --nodegroup-name $NODEGROUP_NAME \
    --region $REGION

# 3. Delete IRSA roles
echo "Cleaning up IRSA roles..."
ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

# Delete S3 role
aws iam detach-role-policy --role-name mlops-irsa-s3-access-role --policy-arn arn:aws:iam::${ACCOUNT_ID}:policy/mlops-irsa-s3-policy 2>/dev/null
aws iam delete-policy --policy-arn arn:aws:iam::${ACCOUNT_ID}:policy/mlops-irsa-s3-policy 2>/dev/null
aws iam delete-role --role-name mlops-irsa-s3-access-role 2>/dev/null

# Delete CloudWatch role
aws iam detach-role-policy --role-name mlops-irsa-cloudwatch-role --policy-arn arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy 2>/dev/null
aws iam delete-role --role-name mlops-irsa-cloudwatch-role 2>/dev/null

# 4. Delete OIDC provider
echo "Deleting OIDC provider..."
OIDC_URL=$(aws eks describe-cluster --name $CLUSTER_NAME --region $REGION --query 'cluster.identity.oidc.issuer' --output text 2>/dev/null | sed 's|https://||')
if [ ! -z "$OIDC_URL" ]; then
    aws iam delete-open-id-connect-provider --open-id-connect-provider-arn arn:aws:iam::${ACCOUNT_ID}:oidc-provider/${OIDC_URL} 2>/dev/null
fi

# 5. Delete cluster
echo "Deleting EKS cluster..."
aws eks delete-cluster --name $CLUSTER_NAME --region $REGION

# Wait for cluster deletion
echo "Waiting for cluster deletion (this may take 10-15 minutes)..."
aws eks wait cluster-deleted --name $CLUSTER_NAME --region $REGION

# 6. Clean up kubeconfig
echo "Cleaning up kubeconfig..."
kubectl config delete-cluster arn:aws:eks:$REGION:${ACCOUNT_ID}:cluster/$CLUSTER_NAME 2>/dev/null
kubectl config delete-context arn:aws:eks:$REGION:${ACCOUNT_ID}:cluster/$CLUSTER_NAME 2>/dev/null
kubectl config unset users.arn:aws:eks:$REGION:${ACCOUNT_ID}:cluster/$CLUSTER_NAME 2>/dev/null

echo "‚úÖ EKS cleanup completed successfully!"
```

---

## 10. B·∫£ng gi√° EKS (ap-southeast-1)

### 10.1. Chi ph√≠ EKS Control Plane

| Component | Gi√° (USD/cluster/gi·ªù) | Gi√° (USD/cluster/th√°ng) | Ghi ch√∫ |
|-----------|------------------------|-------------------------|----------|
| **EKS Control Plane** | $0.10 | $73.00 | Chi ph√≠ c·ªë ƒë·ªãnh b·∫•t k·ªÉ m·ª©c s·ª≠ d·ª•ng |
| **Fargate** | $0.04048/vCPU/gi·ªù | Bi·∫øn ƒë·ªïi | Tr·∫£ theo t√†i nguy√™n pod |
| **EC2 Worker Nodes** | Gi√° EC2 | Bi·∫øn ƒë·ªïi | t2.micro c√≥ FREE tier |

### 10.2. Chi ph√≠ EC2 Worker Nodes

| Lo·∫°i Instance | vCPU | Memory | Gi√° (USD/gi·ªù) | Gi√° (USD/th√°ng) | Free Tier |
|---------------|------|--------|----------------|-----------------|------------|
| **t2.micro** | 1 | 1GB | $0.0116 | $8.50 | ‚úÖ 750h/th√°ng |
| **t3.micro** | 2 | 1GB | $0.0104 | $7.61 | ‚ùå |
| **t3.small** | 2 | 2GB | $0.0208 | $15.22 | ‚ùå |
| **t3.medium** | 2 | 4GB | $0.0416 | $30.45 | ‚ùå |
| **m5.large** | 2 | 8GB | $0.096 | $70.27 | ‚ùå |

### 10.3. Chi ph√≠ VPC Endpoints cho EKS

| Lo·∫°i Endpoint | Gi√° (USD/gi·ªù/endpoint) | Chi ph√≠ h√†ng th√°ng (2 AZ) | Ghi ch√∫ |
|---------------|-------------------------|---------------------|----------|
| **S3 Gateway** | Mi·ªÖn ph√≠ | $0.00 | Kh√¥ng ph√≠ theo gi·ªù |
| **ECR API** | $0.01 | $14.40 | B·∫Øt bu·ªôc cho image pulls |
| **ECR Docker** | $0.01 | $14.40 | B·∫Øt bu·ªôc cho image pulls |
| **CloudWatch Logs** | $0.01 | $14.40 | T√πy ch·ªçn cho logging |
| **EC2** | $0.01 | $14.40 | T√πy ch·ªçn cho instance metadata |

### 10.4. ∆Ø·ªõc t√≠nh chi ph√≠ cho Task 7

**C·∫•u h√¨nh EKS Cluster:**
- Control Plane: 1 cluster
- Worker Nodes: 2x t2.micro instances
- VPC Endpoints: ECR API + ECR Docker
- Storage: 20GB EBS m·ªói node

**Chi ph√≠ h√†ng th√°ng:**

| Component | C·∫•u h√¨nh | Chi ph√≠ h√†ng th√°ng | Gi·∫£m gi√° Free Tier |
|-----------|---------------|--------------|--------------------|
| **EKS Control Plane** | 1 cluster | $73.00 | ‚ùå |
| **t2.micro Instances** | 2x instances (1,500h) | $17.00 | **-$17.00** (MI·ªÑN PH√ç) |
| **EBS Storage** | 40GB gp3 | $3.20 | **-$3.20** (30GB MI·ªÑN PH√ç) |
| **ECR VPC Endpoints** | 2 endpoints √ó 2 AZ | $28.80 | ‚ùå |
| **Data Transfer** | VPC n·ªôi b·ªô | $0.00 | ‚úÖ MI·ªÑN PH√ç |
| **T·ªïng c·ªông** | | **$122.00** | **-$20.20** |
| **Chi ph√≠ th·ª±c t·∫ø** | | | **$101.80** |

### 10.5. So s√°nh chi ph√≠ v·ªõi c√°c l·ª±a ch·ªçn kh√°c

**EKS vs Self-Managed Kubernetes:**

| T√≠nh nƒÉng | EKS | Self-Managed K8s | Ti·∫øt ki·ªám |
|---------|-----|------------------|----------|
| **Control Plane** | $73/th√°ng | $0 (t·ª± l√†m) | -$73 |
| **Qu·∫£n l√Ω h·ªá th·ªëng** | ‚úÖ ƒê∆∞·ª£c qu·∫£n l√Ω | ‚ùå C·∫≠p nh·∫≠t th·ªß c√¥ng | Ti·∫øt ki·ªám th·ªùi gian |
| **B·∫£n v√° b·∫£o m·∫≠t** | ‚úÖ T·ª± ƒë·ªông | ‚ùå Th·ªß c√¥ng | B·∫£o m·∫≠t |
| **Multi-AZ HA** | ‚úÖ S·∫µn c√≥ | ‚ùå Thi·∫øt l·∫≠p ph·ª©c t·∫°p | ƒê·ªô tin c·∫≠y |
| **T√≠ch h·ª£p AWS** | ‚úÖ Native | ‚ùå Th·ªß c√¥ng | D·ªÖ s·ª≠ d·ª•ng |

**EKS vs ECS Fargate:**

| Lo·∫°i workload | Chi ph√≠ EKS | Chi ph√≠ ECS Fargate | Th·∫Øng |
|----------|----------|------------------|--------|
| **APIs nh·ªè (0.25 vCPU)** | $73 + instance | $7.30/th√°ng | **Fargate** |
| **Batch Jobs** | $73 + compute | Tr·∫£ theo l·∫ßn ch·∫°y | **Fargate** |
| **D·ªãch v·ª• lu√¥n ch·∫°y** | $73 + compute | $29.20/th√°ng | **EKS** |
| **·ª®ng d·ª•ng nhi·ªÅu service** | $73 + compute | $N √ó chi ph√≠ service | **EKS** |

### 10.6. Chi ph√≠ Data Transfer

**C√°c t√¨nh hu·ªëng EKS Data Transfer:**

| Lo·∫°i Transfer | Chi ph√≠ | Tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng |
|---------------|------|----------|
| **Pod to Pod (c√πng AZ)** | Mi·ªÖn ph√≠ | Giao ti·∫øp microservices |
| **Pod to Pod (kh√°c AZ)** | $0.01/GB | Tri·ªÉn khai multi-AZ |
| **Pod to Internet** | $0.12/GB | API responses cho users |
| **Pod to S3 (VPC Endpoint)** | Mi·ªÖn ph√≠ | Truy c·∫≠p model/data |
| **Pod to S3 (Internet)** | $0.12/GB | Kh√¥ng c√≥ VPC endpoint |

### 10.7. Chi·∫øn l∆∞·ª£c t·ªëi ∆∞u chi ph√≠

**Right-sizing Instance:**
```bash
# Use Kubernetes resource requests/limits
resources:
  requests:
    cpu: 100m      # 0.1 vCPU
    memory: 128Mi  # 128MB
  limits:
    cpu: 500m      # 0.5 vCPU
    memory: 512Mi  # 512MB
```

**Node Scaling:**
```bash
# Cluster Autoscaler configuration
desired_size = 2
min_size     = 1
max_size     = 10

# Scale down quickly when not needed
scale_down_delay_after_add = "2m"
scale_down_unneeded_time   = "2m"
```

**Spot Instances:**
```bash
# Mix spot v√† on-demand cho cost savings
capacity_type = "SPOT"     # 60-70% savings
# ho·∫∑c
capacity_type = "ON_DEMAND" # Stable pricing
```

### 10.8. T·ªëi ∆∞u h√≥a Free Tier

**L·ª£i √≠ch Free Tier 12 th√°ng:**
- **750 gi·ªù/th√°ng** t2.micro EC2 instances
- **30 GB** EBS General Purpose (SSD) storage
- **2 tri·ªáu** requests t·ªõi Lambda (n·∫øu d√πng cho automation)
- **1 GB** CloudWatch Logs (5GB ƒë·∫ßu mi·ªÖn ph√≠)

**Mi·ªÖn ph√≠ vƒ©nh vi·ªÖn:**
- **1 tri·ªáu** AWS Lambda requests m·ªói th√°ng
- **5 GB** CloudWatch monitoring data
- **S3 transfers** trong c√πng region qua VPC endpoints

{{% notice info %}}
**üí∞ T√≥m t·∫Øt chi ph√≠ cho Task 7:**
- **Chi ph√≠ c·ªë ƒë·ªãnh:** $73/th√°ng (EKS control plane)
- **Chi ph√≠ bi·∫øn ƒë·ªïi:** $28.80/th√°ng (VPC endpoints)
- **Ti·∫øt ki·ªám Free Tier:** $20.20/th√°ng (instances + storage)
- **T·ªïng c·ªông:** **$81.60/th√°ng** v·ªõi free tier optimizations
- **M·ªü r·ªông production:** Th√™m instance types d·ª±a v√†o workload needs
{{% /notice %}}

{{% notice success %}}
**Success tip:** Theo d√µi cluster costs v·ªõi AWS Cost Explorer v√† thi·∫øt l·∫≠p billing alerts. S·ª≠ d·ª•ng eksctl ho·∫∑c Terraform cho infrastructure as code ƒë·ªÉ ƒë·∫£m b·∫£o tri·ªÉn khai consistent v√† reproducible.
{{% /notice %}}

---

## üëâ K·∫øt qu·∫£ Task 7

Sau Task 7, b·∫°n s·∫Ω c√≥ EKS Cluster production-ready, ch·∫°y ho√†n to√†n trong private subnet v√† t√≠ch h·ª£p v·ªõi VPC Endpoints t·ª´ Task 5, ti·∫øt ki·ªám chi ph√≠ NAT Gateway v√† tƒÉng m·ª©c ƒë·ªô b·∫£o m·∫≠t.

### Deliverables Completed

- **EKS Control Plane ACTIVE**: Managed Kubernetes cluster v·ªõi multi-AZ high availability
- **IRSA Configured**: OIDC provider v√† Service Account authentication setup
- **Managed Node Groups**: 2x t2.micro instances (FREE tier) tr·∫£i ƒë·ªÅu tr√™n ‚â•2 AZ
- **VPC Endpoints Integration**: S·ª≠ d·ª•ng ECR, S3 endpoints t·ª´ Task 2 (70% cost savings)
- **Core Add-ons**: VPC CNI, CoreDNS, kube-proxy, metrics-server, EBS CSI driver
- **Secure Pod Access**: Pods c√≥ th·ªÉ access S3/CloudWatch qua IRSA (no hardcoded credentials)
- **kubectl Access**: Local development environment configured v√† tested
- **Cost Optimization**: $117.40/month saved v·ªõi FREE tier + VPC Endpoints

{{% notice success %}}
**üéØ Ready for Next Tasks:**

EKS cluster foundation ƒë√£ s·∫µn s√†ng ƒë·ªÉ deploy:

- ‚úÖ **Task 5**: EKS node groups scaling v√† optimization
- ‚úÖ **Task 6**: ECR repository setup cho container images
- ‚úÖ **Task 7**: Build v√† push inference API container
- ‚úÖ **Task 8**: S3 data storage integration
- ‚úÖ **Task 13**: Deploy inference API l√™n EKS cluster
  {{% /notice %}}

{{% notice warning %}}
**üîê L∆∞u √Ω B·∫£o m·∫≠t & B·∫£o tr√¨:**

- **Public Access**: Gi·ªõi h·∫°n `cluster_endpoint_public_access_cidrs` theo IP ranges th·ª±c t·∫ø trong production
- **Logging**: B·∫≠t t·∫•t c·∫£ control plane logging ƒë·ªÉ audit b·∫£o m·∫≠t  
- **Updates**: Th∆∞·ªùng xuy√™n c·∫≠p nh·∫≠t Kubernetes version v√† add-ons (h√†ng qu√Ω)
- **RBAC**: Tri·ªÉn khai role-based access control ph√π h·ª£p cho team members
- **Monitoring**: Thi·∫øt l·∫≠p alerts cho node health, pod failures, v√† resource usage  
- **Backup**: C√¢n nh·∫Øc EKS cluster backup strategy cho disaster recovery
  {{% /notice %}}

## üé¨ Video th·ª±c hi·ªán Task 7

<div style="position: relative; width: 100%; max-width: 2000px; margin: 0 auto; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe 
    style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" 
    src="https://www.youtube.com/embed/Ueafl18K38Y" 
    title="YouTube video player" 
    frameborder="0" 
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
    referrerpolicy="strict-origin-when-cross-origin" 
    allowfullscreen>
  </iframe>
</div>

---

**Next Step**: [Task 08: Deploy Kubernetes](../8-deploy-kubernetes)